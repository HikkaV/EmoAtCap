{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "legal-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-minister",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## change only the next cell for personalized configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = \"../data/imdb/imdb/\"\n",
    "path_annotations = \"../data/emo-at-cap/emo-at-cap.csv\"\n",
    "mode = 0\n",
    "size = (400, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-notebook",
   "metadata": {},
   "source": [
    "## actual annotator\n",
    "### mode=0 -> create annotation, mode=1 -> show existing annotations and change on premiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lined-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_annotations):\n",
    "    df = pd.DataFrame(columns=['image_name','annotation'])\n",
    "    df.to_csv(path_annotations, index=False)\n",
    "all_pathes = os.listdir(path_images)\n",
    "new_images = []\n",
    "new_annotations = []\n",
    "if mode==0:\n",
    "    df = pd.read_csv(path_annotations)\n",
    "    print('So far {} images were annotated'.format(len(df)))\n",
    "    tmp_df = pd.DataFrame(columns=df.columns.tolist())\n",
    "    images = df['image_name'].values\n",
    "    to_annotate = set(all_pathes).difference(images) if images.size!=0 else all_pathes\n",
    "    if to_annotate:\n",
    "        for image in to_annotate:\n",
    "            display(Image.open(os.path.join(path_images,image)).resize(size))\n",
    "            annotation = str(input()).strip()\n",
    "            clear_output()\n",
    "            if annotation and annotation!='exit':\n",
    "                new_images.append(image)\n",
    "                new_annotations.append(annotation)\n",
    "            elif annotation=='exit':\n",
    "                break\n",
    "        tmp_df['image_name'] = new_images\n",
    "        tmp_df['annotation'] = new_annotations\n",
    "        df = df.append(tmp_df)\n",
    "        df.to_csv(path_annotations, index=False)\n",
    "                \n",
    "    else:\n",
    "        print('All the images are annotated. If you want to change them and view please use mode=1')\n",
    "elif mode==1:\n",
    "    df = pd.read_csv(path_annotations)\n",
    "    print('So far {} images were annotated'.format(len(df)))\n",
    "    images = df['image_name'].values\n",
    "    annotations = df['annotation'].values\n",
    "    for annotation, image in zip(annotations,images):\n",
    "        display(Image.open(os.path.join(path_images,image)))\n",
    "        print(annotation)\n",
    "        annotation = str(input()).strip()\n",
    "        clear_output()\n",
    "        if annotation and annotation!='exit':\n",
    "            new_images.append(image)\n",
    "            new_annotations.append(annotation)\n",
    "        elif annotation=='exit':\n",
    "            break\n",
    "    if new_images and new_annotations:\n",
    "        ordered_images = df[df['image_name'].isin(new_images)]['image_name'].values\n",
    "        dict_ordering = dict([(i,c) for c,i in enumerate(new_images)])\n",
    "        indexes = [dict_ordering.get(i) for i in ordered_images]\n",
    "        new_annotations = np.array(new_annotations)[indexes]\n",
    "        df.loc[df['image_name'].isin(new_images), 'annotation'] = new_annotations\n",
    "    df = df.reset_index().drop(columns='index')\n",
    "    df.to_csv(path_annotations, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "serious-accessory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3840"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "guilty-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>annotation</th>\n",
       "      <th>human_sentiment</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm1055413_rm704041984_1977-4-2_2014.jpg</td>\n",
       "      <td>The man is running from something</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000113_rm1310297088_1964-7-26_2006.jpg</td>\n",
       "      <td>The worried woman is carrying for the other woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0001713_rm271353088_1970-6-4_1995.jpg</td>\n",
       "      <td>The man and the woman are trying to protect th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm4237013_rm663142144_1985-0-0_2003.jpg</td>\n",
       "      <td>The man is flirting with the woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000113_rm1350277376_1964-7-26_2007.jpg</td>\n",
       "      <td>The man and the woman are surprised by something</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>nm0000704_rm3825510400_1981-1-28_2011.jpg</td>\n",
       "      <td>A couple is happily holding a baby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>._nm1715118_rm1685958144_1987-7-16_2008.jpg</td>\n",
       "      <td>A couple is enjoying the atmosphere and drinki...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>._nm0815418_rm3261959424_1969-8-16_2006.jpg</td>\n",
       "      <td>Three men are surprised with something while d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>._nm0285913_rm780652032_1979-1-15_2013.jpg</td>\n",
       "      <td>Two men are serious during their conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>nm0192505_rm513978880_1985-11-30_2007.jpg</td>\n",
       "      <td>Two women are disgusted with some clothes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3840 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_name  \\\n",
       "0         nm1055413_rm704041984_1977-4-2_2014.jpg   \n",
       "1       nm0000113_rm1310297088_1964-7-26_2006.jpg   \n",
       "2         nm0001713_rm271353088_1970-6-4_1995.jpg   \n",
       "3         nm4237013_rm663142144_1985-0-0_2003.jpg   \n",
       "4       nm0000113_rm1350277376_1964-7-26_2007.jpg   \n",
       "...                                           ...   \n",
       "3835    nm0000704_rm3825510400_1981-1-28_2011.jpg   \n",
       "3836  ._nm1715118_rm1685958144_1987-7-16_2008.jpg   \n",
       "3837  ._nm0815418_rm3261959424_1969-8-16_2006.jpg   \n",
       "3838   ._nm0285913_rm780652032_1979-1-15_2013.jpg   \n",
       "3839    nm0192505_rm513978880_1985-11-30_2007.jpg   \n",
       "\n",
       "                                             annotation human_sentiment Done  \n",
       "0                     The man is running from something             NaN    -  \n",
       "1     The worried woman is carrying for the other woman             NaN    -  \n",
       "2     The man and the woman are trying to protect th...             NaN    -  \n",
       "3                    The man is flirting with the woman             NaN    -  \n",
       "4      The man and the woman are surprised by something             NaN    -  \n",
       "...                                                 ...             ...  ...  \n",
       "3835                 A couple is happily holding a baby             NaN  NaN  \n",
       "3836  A couple is enjoying the atmosphere and drinki...             NaN  NaN  \n",
       "3837  Three men are surprised with something while d...             NaN  NaN  \n",
       "3838      Two men are serious during their conversation             NaN  NaN  \n",
       "3839          Two women are disgusted with some clothes             NaN  NaN  \n",
       "\n",
       "[3840 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-therapy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
