{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a82861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fd949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from keras_preprocessing import image as im\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f9947",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0cdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path, annotations_path):\n",
    "    df = pd.read_csv(annotations_path)\n",
    "    df = df[~df['human_sentiment'].isna()]\n",
    "    in_folder = os.listdir(image_path)\n",
    "    df.loc[df['image_name'].isin(in_folder), 'image_name'] = \\\n",
    "    df.loc[df['image_name'].isin(in_folder), 'image_name'].apply(lambda x: os.path.join(image_path,x))\n",
    "    images = []\n",
    "    for image_name in df['image_name'].values:\n",
    "        images.append(np.array(im.load_img(image_name, target_size=(224,224))))\n",
    "    images = np.array(images)\n",
    "    images = images/255\n",
    "    annotations = df['annotation'].str.lower().values\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d042e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, annotations = load_data(\"../../../images/\", '../../../emo-at-cap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119b237",
   "metadata": {},
   "source": [
    "# Processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72d7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5ea8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3c8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [tokenizer.tokenize(i) for i in annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e5acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens, unique_counts = np.unique(np.hstack(tokenized), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308e566e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3261),\n",
       " ('is', 2031),\n",
       " ('man', 1905),\n",
       " ('and', 1536),\n",
       " ('woman', 1361),\n",
       " ('are', 1036),\n",
       " ('a', 963),\n",
       " ('to', 891),\n",
       " ('looks', 751),\n",
       " ('happy', 705),\n",
       " ('with', 547),\n",
       " ('something', 480),\n",
       " ('men', 478),\n",
       " ('of', 463),\n",
       " ('two', 408),\n",
       " ('other', 361),\n",
       " ('people', 343),\n",
       " ('couple', 334),\n",
       " (',', 330),\n",
       " ('in', 278),\n",
       " ('look', 270),\n",
       " ('because', 265),\n",
       " ('they', 256),\n",
       " ('about', 247),\n",
       " ('on', 246),\n",
       " ('at', 192),\n",
       " ('trying', 190),\n",
       " ('serious', 189),\n",
       " ('women', 184),\n",
       " ('each', 179),\n",
       " ('together', 176),\n",
       " ('by', 175),\n",
       " ('having', 171),\n",
       " ('flirting', 165),\n",
       " ('he', 155),\n",
       " ('smiling', 151),\n",
       " ('arguing', 141),\n",
       " ('angry', 140),\n",
       " ('scared', 138),\n",
       " ('worried', 137),\n",
       " ('hugging', 135),\n",
       " ('surprised', 134),\n",
       " ('calm', 133),\n",
       " ('company', 131),\n",
       " ('her', 129),\n",
       " ('group', 123),\n",
       " ('for', 121),\n",
       " ('she', 117),\n",
       " ('looking', 117),\n",
       " ('his', 115)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(unique_tokens, unique_counts)), key = lambda x: x[1])[::-1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e11934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2162"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca9f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token = '<PAD>'\n",
    "start_token = '<S>'\n",
    "end_token = '<E>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e382f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict(zip(unique_tokens,list(range(3,len(unique_tokens)+3))))\n",
    "vocab[pad_token] = 0\n",
    "vocab[start_token] = 1\n",
    "vocab[end_token] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a084dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab = dict([(v,k) for k,v in vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9dc18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_special_tokens = lambda x: [start_token] + x + [end_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "242ddaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = list(map(add_special_tokens,tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be7e6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(max(tokenized, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e71af0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = list(map(lambda x: [vocab[i] for i in x],tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17cd3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = tf.keras.preprocessing.sequence.pad_sequences(indexed, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "978c23b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f684c",
   "metadata": {},
   "source": [
    "# Simple model without additional features, transfer learning and attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc2781d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_size(x, f, s, padding='same'):\n",
    "    p = 2 if padding=='same' else 1\n",
    "    return (x-f+2)/s+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735eddb6",
   "metadata": {},
   "source": [
    "### Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc7ac17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(tf.keras.Model):\n",
    "    def __init__(self, image_shape=(224,224,3)):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        self.input_conv = tf.keras.layers.Conv2D(filters=128, kernel_size=7, input_shape=image_shape, activation='relu',\n",
    "                           padding='same', name='input_conv', strides=(1,1))\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=7, activation='relu',\n",
    "                               padding='same', name='conv1', strides=(2,2))\n",
    "        self.batch_norm1 =  tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation='relu',\n",
    "                               padding='same', name='conv2', strides=(2,2))\n",
    "        self.batch_norm2 =  tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu',\n",
    "                               padding='same', name='conv3', strides=(2,2))\n",
    "        self.batch_norm3 =  tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu',\n",
    "                               padding='same', name='conv4', strides=(2,2))\n",
    "        self.batch_norm4 =  tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv5 = tf.keras.layers.Conv2D(filters=4, kernel_size=3, activation='relu',\n",
    "                               padding='same', name='conv5', strides=(2,2))\n",
    "        self.batch_norm5 =  tf.keras.layers.BatchNormalization()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(filters=4, kernel_size=3, activation='relu',\n",
    "                               padding='same', name='conv5', strides=(2,2))\n",
    "        self.batch_norm6 =  tf.keras.layers.BatchNormalization()\n",
    "       \n",
    "        self.flatten = tf.keras.layers.Flatten(name='final_code')\n",
    "    \n",
    "    def call(self, input):\n",
    "        conv1_out = self.batch_norm1(self.conv1(self.input_conv(input)))\n",
    "        conv2_out = self.batch_norm2(self.conv2(conv1_out))\n",
    "        conv3_out = self.batch_norm3(self.conv3(conv2_out))\n",
    "        conv4_out = self.batch_norm4(self.conv4(conv3_out))\n",
    "        conv5_out = self.batch_norm5(self.conv5(conv4_out))\n",
    "        conv6_out = self.batch_norm6(self.conv6(conv4_out))\n",
    "        result = [self.flatten(conv5_out),self.flatten(conv6_out)]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3eeed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoder = ConvEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e21e4dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv_encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_res = conv_encoder(np.expand_dims(images[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d3d839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 196), dtype=float32, numpy=\n",
       " array([[0.00000000e+00, 1.27262319e-04, 5.52950427e-03, 1.28674146e-04,\n",
       "         0.00000000e+00, 0.00000000e+00, 4.41587623e-03, 7.41579104e-04,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.40692154e-03, 9.76479845e-04,\n",
       "         0.00000000e+00, 0.00000000e+00, 4.24025906e-03, 0.00000000e+00,\n",
       "         6.33005984e-04, 0.00000000e+00, 6.23816717e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.29834395e-03, 1.34039321e-03,\n",
       "         2.53455737e-03, 0.00000000e+00, 2.49279244e-03, 0.00000000e+00,\n",
       "         9.31133865e-04, 0.00000000e+00, 1.04052108e-02, 3.84958833e-03,\n",
       "         2.17406475e-03, 0.00000000e+00, 8.96684267e-03, 2.14515137e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 6.66103559e-03, 0.00000000e+00,\n",
       "         2.40253098e-03, 0.00000000e+00, 9.93811991e-03, 7.70624308e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 8.51054024e-03, 4.06292733e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.39682687e-03, 0.00000000e+00, 4.51526977e-03, 7.13383852e-05,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.12337126e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 6.31094445e-04, 2.77641648e-03,\n",
       "         8.81106753e-05, 0.00000000e+00, 1.40788723e-02, 8.05991143e-03,\n",
       "         2.31988495e-03, 0.00000000e+00, 6.30953908e-03, 3.32888099e-03,\n",
       "         1.00918273e-02, 0.00000000e+00, 4.24751034e-03, 0.00000000e+00,\n",
       "         7.88395200e-03, 0.00000000e+00, 1.75991040e-02, 0.00000000e+00,\n",
       "         1.08318031e-02, 0.00000000e+00, 3.26958694e-03, 0.00000000e+00,\n",
       "         6.89618476e-03, 0.00000000e+00, 1.25928465e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 8.79297126e-03, 5.20022865e-03,\n",
       "         6.31635601e-04, 0.00000000e+00, 2.81858677e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.65627133e-02, 8.81633535e-03,\n",
       "         1.14121865e-02, 0.00000000e+00, 6.54487452e-03, 9.67635121e-03,\n",
       "         1.65774766e-03, 0.00000000e+00, 1.62074659e-02, 1.14512723e-02,\n",
       "         7.82766938e-03, 0.00000000e+00, 3.63013684e-03, 0.00000000e+00,\n",
       "         1.02182664e-02, 0.00000000e+00, 1.47313764e-02, 7.38001103e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 9.36315395e-03, 4.71708318e-03,\n",
       "         5.54917473e-03, 0.00000000e+00, 2.04710662e-03, 3.65936966e-03,\n",
       "         5.81603125e-03, 0.00000000e+00, 1.42133133e-02, 1.12961205e-02,\n",
       "         3.48304352e-03, 0.00000000e+00, 1.61803961e-02, 8.10769200e-03,\n",
       "         6.50612824e-03, 0.00000000e+00, 1.92469154e-02, 2.95765628e-03,\n",
       "         6.27021259e-03, 0.00000000e+00, 2.87977653e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.02253035e-02, 0.00000000e+00,\n",
       "         5.82416760e-05, 0.00000000e+00, 1.06477970e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.57106165e-02, 4.29381197e-03,\n",
       "         2.74920953e-03, 0.00000000e+00, 1.28260842e-02, 7.76204886e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.41864438e-02, 1.93819811e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00203697e-02, 7.30881933e-03,\n",
       "         1.07551767e-02, 0.00000000e+00, 3.70840169e-03, 0.00000000e+00,\n",
       "         2.05465443e-02, 0.00000000e+00, 2.43538842e-02, 1.42461741e-02,\n",
       "         1.58952046e-02, 0.00000000e+00, 2.35684291e-02, 1.33365318e-02,\n",
       "         1.55032957e-02, 0.00000000e+00, 1.70167964e-02, 1.65996384e-02,\n",
       "         1.70990955e-02, 0.00000000e+00, 2.12417450e-02, 1.30410166e-02,\n",
       "         1.75210964e-02, 0.00000000e+00, 2.07915008e-02, 1.33654959e-02,\n",
       "         1.77621339e-02, 0.00000000e+00, 2.54684389e-02, 1.64951850e-02,\n",
       "         1.32914530e-02, 0.00000000e+00, 1.27200764e-02, 1.18162821e-03]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 196), dtype=float32, numpy=\n",
       " array([[0.        , 0.        , 0.00965443, 0.00947106, 0.        ,\n",
       "         0.        , 0.01065631, 0.01201764, 0.        , 0.        ,\n",
       "         0.01034249, 0.01346755, 0.        , 0.        , 0.01352075,\n",
       "         0.01223376, 0.        , 0.        , 0.01332489, 0.01110667,\n",
       "         0.        , 0.        , 0.00496412, 0.00864454, 0.        ,\n",
       "         0.00033037, 0.00632119, 0.00702831, 0.        , 0.        ,\n",
       "         0.01153412, 0.00675371, 0.        , 0.        , 0.00902396,\n",
       "         0.01319488, 0.        , 0.        , 0.00947196, 0.01091181,\n",
       "         0.        , 0.        , 0.0134529 , 0.02199901, 0.        ,\n",
       "         0.        , 0.00130223, 0.01793948, 0.        , 0.        ,\n",
       "         0.00533988, 0.01178331, 0.        , 0.00035481, 0.00805735,\n",
       "         0.00754343, 0.        , 0.        , 0.00814877, 0.01972518,\n",
       "         0.        , 0.        , 0.00756272, 0.01816089, 0.        ,\n",
       "         0.        , 0.00803914, 0.01074478, 0.        , 0.        ,\n",
       "         0.00887061, 0.01822258, 0.        , 0.        , 0.00816138,\n",
       "         0.01031002, 0.        , 0.        , 0.00872028, 0.00916019,\n",
       "         0.        , 0.00435379, 0.00827197, 0.00967552, 0.        ,\n",
       "         0.        , 0.01349652, 0.01800798, 0.        , 0.        ,\n",
       "         0.01305856, 0.0208541 , 0.        , 0.        , 0.0113213 ,\n",
       "         0.01354864, 0.        , 0.        , 0.01631416, 0.01758373,\n",
       "         0.        , 0.        , 0.01908535, 0.02884654, 0.        ,\n",
       "         0.        , 0.0093606 , 0.01759848, 0.        , 0.        ,\n",
       "         0.01078737, 0.02055099, 0.        , 0.        , 0.01331443,\n",
       "         0.01851585, 0.        , 0.        , 0.01038994, 0.0184709 ,\n",
       "         0.        , 0.        , 0.01278397, 0.01893135, 0.        ,\n",
       "         0.        , 0.01224753, 0.01873025, 0.        , 0.        ,\n",
       "         0.02131921, 0.01733033, 0.        , 0.        , 0.01098765,\n",
       "         0.0135914 , 0.        , 0.        , 0.01251682, 0.02109957,\n",
       "         0.        , 0.        , 0.0138928 , 0.0099914 , 0.        ,\n",
       "         0.        , 0.01503324, 0.02025461, 0.        , 0.        ,\n",
       "         0.01802926, 0.01772636, 0.        , 0.        , 0.01077743,\n",
       "         0.01363916, 0.        , 0.        , 0.0114646 , 0.0213065 ,\n",
       "         0.        , 0.        , 0.00776294, 0.02424687, 0.        ,\n",
       "         0.00807908, 0.02255242, 0.01164083, 0.00668888, 0.        ,\n",
       "         0.00955814, 0.00603653, 0.00281965, 0.        , 0.01405024,\n",
       "         0.00965869, 0.00826201, 0.        , 0.00737073, 0.01239048,\n",
       "         0.00417218, 0.        , 0.00909139, 0.00710423, 0.00477261,\n",
       "         0.        , 0.00604138, 0.00971636, 0.00309902, 0.        ,\n",
       "         0.01008951, 0.00582208, 0.00202966, 0.00384739, 0.00422414,\n",
       "         0.02115184]], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a14c39",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56e9761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(tf.keras.Model):\n",
    "    def __init__(self, max_tokens, lstm_units):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.embeddings = tf.keras.layers.Embedding(input_dim=max_tokens+1, output_dim=128, name='embeddings')\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name='layer_normalization')\n",
    "        self.lstm = tf.keras.layers.LSTM(units=lstm_units, return_state=True, name='lstm_decoder')\n",
    "        self.output_dense = tf.keras.layers.Dense(units=max_tokens)\n",
    "        \n",
    "    def call(self, input, features):\n",
    "        embedded = self.embeddings(input)\n",
    "        result_lstm, state_h, state_c = self.lstm(embedded, initial_state=features)\n",
    "        normalized = self.layer_norm(result_lstm)\n",
    "        logits = self.output_dense(normalized)\n",
    "        return logits, [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "973e9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_decoder = LSTMDecoder(len(inverse_vocab), conv_res[0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fced5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2165), dtype=float32, numpy=\n",
       " array([[ 0.98470294, -0.2562873 , -0.15531676, ...,  0.13696869,\n",
       "         -0.34102824,  0.16832274]], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1, 196), dtype=float32, numpy=\n",
       "  array([[ 5.40204113e-03,  9.26242676e-03, -3.24909692e-03,\n",
       "          -3.44752078e-03, -8.29503592e-03,  1.33345195e-03,\n",
       "          -8.13061092e-03, -1.90062309e-03,  4.38818336e-03,\n",
       "           6.07338408e-03,  1.83624052e-05,  4.12985357e-03,\n",
       "           2.72139511e-03,  6.26521325e-03, -6.96459087e-03,\n",
       "          -2.87974632e-04,  1.41559413e-03,  2.32430105e-03,\n",
       "          -1.54397672e-03,  1.23339123e-03, -5.78529085e-04,\n",
       "          -2.77572637e-03, -3.74819199e-03,  7.76082103e-04,\n",
       "           6.11304946e-04,  8.84504989e-04,  1.25597836e-02,\n",
       "           4.81049111e-03,  2.81226193e-03,  4.43036854e-03,\n",
       "           5.70475706e-04,  1.94471190e-03, -4.27779829e-04,\n",
       "           6.46081707e-03,  6.68543670e-03,  1.04081277e-02,\n",
       "           8.11339263e-03, -3.23595782e-03, -1.74678012e-03,\n",
       "          -1.63269229e-02,  8.19474272e-03, -8.72642454e-03,\n",
       "           2.55852495e-03, -8.36286228e-04,  6.46383734e-03,\n",
       "          -1.36285427e-03,  1.77623215e-03, -2.08901777e-03,\n",
       "          -9.18619509e-04,  1.46452116e-03, -4.54870751e-03,\n",
       "           9.28440504e-03,  1.01608457e-03,  1.58736464e-02,\n",
       "           4.88181645e-03,  2.57673091e-04, -1.20145129e-02,\n",
       "           1.07462620e-02, -5.29148290e-03, -9.84288752e-03,\n",
       "          -1.56283480e-04,  3.61737004e-03,  6.36465801e-03,\n",
       "           3.36456485e-03, -5.07240649e-03, -5.38672175e-05,\n",
       "           5.53145539e-03, -7.69531401e-03, -8.82263936e-04,\n",
       "          -9.22033389e-04,  5.53327519e-03, -4.25181864e-03,\n",
       "          -2.11969973e-03,  9.99159738e-03,  4.77936864e-03,\n",
       "           8.67454149e-03, -1.57998279e-02, -6.66226819e-03,\n",
       "           8.25044641e-04,  7.13335117e-03, -8.61739833e-03,\n",
       "           6.10762695e-03, -8.26816820e-03, -6.35631382e-03,\n",
       "           1.38122039e-02,  1.79189607e-04,  3.15106218e-03,\n",
       "           4.49272059e-03, -3.92499287e-03, -7.40054389e-03,\n",
       "          -8.98788712e-05,  1.06370226e-02, -4.41831490e-03,\n",
       "           1.30162099e-02,  1.27601065e-02,  4.23807837e-03,\n",
       "          -4.82589100e-03,  6.79754792e-03,  9.34880343e-04,\n",
       "          -7.22786738e-03,  4.00231360e-03, -7.03088148e-03,\n",
       "          -5.07143699e-03, -2.54738005e-03, -5.96521050e-03,\n",
       "           6.48368197e-03, -2.95719889e-04, -9.49476380e-03,\n",
       "           4.49751318e-03,  6.34766370e-03, -8.02330393e-03,\n",
       "           1.85333774e-04,  1.89229078e-03, -4.88581695e-03,\n",
       "          -3.17005580e-03,  9.95801762e-03,  2.39079795e-03,\n",
       "          -2.43665112e-04,  7.53791304e-03,  5.13474770e-05,\n",
       "          -7.45680649e-03,  5.67606557e-03, -2.02517826e-04,\n",
       "           4.82837018e-03,  2.75462167e-03, -5.95618878e-03,\n",
       "          -1.07593648e-03, -3.87463812e-03,  6.95184572e-03,\n",
       "          -2.14312677e-04, -1.60388164e-02,  3.29999323e-03,\n",
       "           8.80837068e-03,  4.51642927e-03,  2.63823057e-03,\n",
       "          -3.59803205e-03,  5.01330337e-03, -7.26517662e-03,\n",
       "           4.10887063e-04, -4.78521368e-04, -7.62201194e-03,\n",
       "           3.50500317e-03,  1.07134976e-04,  6.12438831e-04,\n",
       "          -5.49239479e-03,  5.44550689e-03, -7.70784728e-03,\n",
       "          -1.46678649e-03, -7.09143328e-03, -1.85908633e-03,\n",
       "          -1.01800542e-03, -1.28666742e-03,  9.55411885e-03,\n",
       "          -2.13978565e-04, -2.57018628e-03, -4.04423941e-03,\n",
       "          -5.60012134e-03, -1.22703018e-03,  1.39609911e-03,\n",
       "           2.42300075e-03,  8.44124984e-03,  2.55006715e-03,\n",
       "          -1.84884598e-03,  1.03755250e-04, -5.93011081e-03,\n",
       "           6.86345436e-03, -3.58147523e-03,  1.21348742e-02,\n",
       "           1.83964812e-03,  8.71366262e-03, -7.46935606e-03,\n",
       "           3.31918756e-03,  4.78588743e-03,  1.41643919e-03,\n",
       "          -7.97949824e-03, -5.20854883e-05, -6.66456250e-03,\n",
       "           1.78459834e-03, -9.21710674e-03,  8.24637897e-03,\n",
       "          -1.47498026e-03, -5.05640544e-03,  4.88266960e-04,\n",
       "           3.39705846e-03,  4.74913232e-03,  1.89805171e-03,\n",
       "          -2.85878289e-03,  4.50799154e-04, -1.48788397e-03,\n",
       "          -5.35714068e-03, -5.08931046e-03,  7.32784206e-03,\n",
       "          -1.01961510e-03,  3.64895049e-03,  3.08912271e-03,\n",
       "           1.28355976e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1, 196), dtype=float32, numpy=\n",
       "  array([[ 1.07127912e-02,  1.88902840e-02, -6.48484519e-03,\n",
       "          -6.89251488e-03, -1.65207945e-02,  2.67038378e-03,\n",
       "          -1.62346270e-02, -3.83616704e-03,  8.65797978e-03,\n",
       "           1.20237991e-02,  3.63163963e-05,  8.28316342e-03,\n",
       "           5.42897591e-03,  1.26117077e-02, -1.41565409e-02,\n",
       "          -5.77794970e-04,  2.82939826e-03,  4.67126584e-03,\n",
       "          -3.09551763e-03,  2.48135882e-03, -1.14732771e-03,\n",
       "          -5.61349466e-03, -7.46455370e-03,  1.54562877e-03,\n",
       "           1.20171427e-03,  1.75011286e-03,  2.50723492e-02,\n",
       "           9.71428864e-03,  5.56021137e-03,  8.96422844e-03,\n",
       "           1.13141036e-03,  3.85495182e-03, -8.45630828e-04,\n",
       "           1.29478415e-02,  1.33136632e-02,  2.09138244e-02,\n",
       "           1.63549613e-02, -6.39291666e-03, -3.49053694e-03,\n",
       "          -3.21952477e-02,  1.64324306e-02, -1.74387414e-02,\n",
       "           5.10204211e-03, -1.66633958e-03,  1.31709678e-02,\n",
       "          -2.71518668e-03,  3.53859784e-03, -4.14343085e-03,\n",
       "          -1.81983714e-03,  2.94456910e-03, -9.18231346e-03,\n",
       "           1.85705926e-02,  2.02997192e-03,  3.16775925e-02,\n",
       "           9.66164656e-03,  5.08861034e-04, -2.35029105e-02,\n",
       "           2.11455822e-02, -1.06218662e-02, -1.96716543e-02,\n",
       "          -3.11659591e-04,  7.25722080e-03,  1.25331702e-02,\n",
       "           6.84922747e-03, -1.01867709e-02, -1.08618900e-04,\n",
       "           1.10607045e-02, -1.52778160e-02, -1.75690849e-03,\n",
       "          -1.85727712e-03,  1.10002961e-02, -8.60675890e-03,\n",
       "          -4.25499398e-03,  1.98115651e-02,  9.52674076e-03,\n",
       "           1.73657853e-02, -3.16880308e-02, -1.31828627e-02,\n",
       "           1.65196531e-03,  1.41526461e-02, -1.73433386e-02,\n",
       "           1.22195175e-02, -1.66571215e-02, -1.27015505e-02,\n",
       "           2.76040453e-02,  3.52746050e-04,  6.29548030e-03,\n",
       "           8.93806759e-03, -7.88348820e-03, -1.46923810e-02,\n",
       "          -1.78392613e-04,  2.14869119e-02, -8.91089253e-03,\n",
       "           2.59675626e-02,  2.54968982e-02,  8.49076360e-03,\n",
       "          -9.74330679e-03,  1.35563165e-02,  1.85795384e-03,\n",
       "          -1.44362757e-02,  8.03675223e-03, -1.41006755e-02,\n",
       "          -1.00445468e-02, -5.14768716e-03, -1.19714811e-02,\n",
       "           1.29794916e-02, -5.86657203e-04, -1.89167410e-02,\n",
       "           8.92254710e-03,  1.25855468e-02, -1.58765893e-02,\n",
       "           3.65943764e-04,  3.81812290e-03, -9.88304522e-03,\n",
       "          -6.28815684e-03,  1.97059195e-02,  4.77078604e-03,\n",
       "          -4.85446071e-04,  1.53429508e-02,  1.03598330e-04,\n",
       "          -1.47140762e-02,  1.13580143e-02, -4.01990343e-04,\n",
       "           9.60867666e-03,  5.50766103e-03, -1.18701551e-02,\n",
       "          -2.16583023e-03, -7.68511975e-03,  1.38884531e-02,\n",
       "          -4.26934712e-04, -3.19821872e-02,  6.63256459e-03,\n",
       "           1.76665839e-02,  9.09403712e-03,  5.34280390e-03,\n",
       "          -7.09515810e-03,  9.96109657e-03, -1.44484276e-02,\n",
       "           8.21281574e-04, -9.55970900e-04, -1.52706970e-02,\n",
       "           6.87912200e-03,  2.15140113e-04,  1.24898646e-03,\n",
       "          -1.10823922e-02,  1.07110953e-02, -1.53844729e-02,\n",
       "          -2.92866491e-03, -1.40979057e-02, -3.71573539e-03,\n",
       "          -2.05631065e-03, -2.57108547e-03,  1.93220936e-02,\n",
       "          -4.31760884e-04, -5.16114151e-03, -8.12301505e-03,\n",
       "          -1.10921105e-02, -2.47138250e-03,  2.80975620e-03,\n",
       "           4.84970352e-03,  1.69797335e-02,  5.10720816e-03,\n",
       "          -3.70708643e-03,  2.05544173e-04, -1.19440258e-02,\n",
       "           1.37889907e-02, -7.15351757e-03,  2.42699087e-02,\n",
       "           3.65402945e-03,  1.73443407e-02, -1.50390323e-02,\n",
       "           6.69983588e-03,  9.51055996e-03,  2.82920361e-03,\n",
       "          -1.60866231e-02, -1.04811967e-04, -1.33619905e-02,\n",
       "           3.60009517e-03, -1.85028519e-02,  1.67520791e-02,\n",
       "          -2.93348823e-03, -1.01150321e-02,  9.82122612e-04,\n",
       "           6.85112597e-03,  9.36998427e-03,  3.73564148e-03,\n",
       "          -5.75379422e-03,  8.94438243e-04, -3.00494162e-03,\n",
       "          -1.06575685e-02, -1.02108857e-02,  1.45136304e-02,\n",
       "          -2.04131287e-03,  7.31741264e-03,  6.16871379e-03,\n",
       "           2.54619978e-02]], dtype=float32)>])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_decoder(np.expand_dims(padded[0],axis=0), conv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6b883",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "907088e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a306a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none',\n",
    "                                                                         from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cfc759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(real, vocab[pad_token]))\n",
    "        loss_ = loss_object(real, pred)\n",
    "\n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "896629c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, target, lengths, optimizer):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        initial_state = conv_encoder(image)\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        batched_loss = []\n",
    "        for t in range(1, target.shape[1]):\n",
    "            \n",
    "            dec_input = tf.expand_dims(target[:, t-1], 1)\n",
    "            result, initial_state = lstm_decoder(input=dec_input, features=initial_state)\n",
    "\n",
    "            batched_loss.append(loss_function(target[:, t], result))\n",
    "        batched_loss = tf.reshape(tf.stack(batched_loss), shape=target[:,1:].shape)\n",
    "        batched_loss = tf.reduce_sum(batched_loss, axis=1)\n",
    "        lengths = tf.cast(lengths, dtype=batched_loss.dtype)\n",
    "        loss = tf.reduce_mean(batched_loss / lengths)\n",
    "\n",
    "    perplexity = tf.exp(loss)\n",
    "\n",
    "    variables = conv_encoder.trainable_variables + lstm_decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bd7e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def evaluate(image, target, lengths, optimizer):\n",
    "\n",
    "    initial_state = conv_encoder(image)\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    batched_loss = []\n",
    "    for t in range(1, target.shape[1]):\n",
    "\n",
    "        dec_input = tf.expand_dims(target[:, t-1], 1)\n",
    "        result, initial_state = lstm_decoder(input=dec_input, features=initial_state)\n",
    "\n",
    "        batched_loss.append(loss_function(target[:, t], result))\n",
    "\n",
    "    batched_loss = tf.reshape(tf.stack(batched_loss), shape=target[:,1:].shape)\n",
    "    batched_loss = tf.reduce_sum(batched_loss, axis=1)\n",
    "    lengths = tf.cast(lengths, dtype=batched_loss.dtype)\n",
    "    loss = tf.reduce_mean(batched_loss / lengths)\n",
    "\n",
    "    perplexity = tf.exp(loss)\n",
    "\n",
    "\n",
    "    return loss, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37a9c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_sequences, test_sequences =  train_test_split(images, padded, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "694510b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = (train_sequences!=vocab[pad_token]).sum(axis=1)-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a96dde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length = (test_sequences!=vocab[pad_token]).sum(axis=1)-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cae61d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size= 64\n",
    "train_images = np.array(np.array_split(train_images, len(train_images)//batch_size))\n",
    "test_images = np.array(np.array_split(test_images, len(test_images)//batch_size))\n",
    "train_sequences = np.array(np.array_split(train_sequences, len(train_sequences)//batch_size))\n",
    "test_sequences = np.array(np.array_split(test_sequences, len(test_sequences)//batch_size))\n",
    "train_length = np.array(np.array_split(train_length, len(train_length)//batch_size))\n",
    "test_length = np.array(np.array_split(test_length, len(test_length)//batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35f9d25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54, 64, 224, 224, 3), (54, 64, 37), (54, 64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_sequences.shape, train_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f8e46ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (4.61.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "290584c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f88dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [02:15,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0; Train loss : 7.964125156402588; Train perplexity : 17854.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.7490072250366211; Test perplexity : 319.35784912109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:25,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1; Train loss : 6.31256628036499; Train perplexity : 1864.590576171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.6238366365432739; Test perplexity : 80.35478210449219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:25,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 2; Train loss : 5.4418745040893555; Train perplexity : 606.2158813476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.5585781335830688; Test perplexity : 39.258155822753906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 3; Train loss : 4.924441814422607; Train perplexity : 320.242919921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.5138434171676636; Test perplexity : 24.06816291809082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 4; Train loss : 4.539194107055664; Train perplexity : 200.29571533203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.4802291691303253; Test perplexity : 16.642854690551758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 5; Train loss : 4.232934951782227; Train perplexity : 138.24436950683594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.45290929079055786; Test perplexity : 12.333497047424316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 6; Train loss : 3.9789860248565674; Train perplexity : 101.7147445678711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.4304272532463074; Test perplexity : 9.643580436706543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 7; Train loss : 3.767735004425049; Train perplexity : 78.76109313964844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.41257762908935547; Test perplexity : 7.935382843017578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 8; Train loss : 3.5917928218841553; Train perplexity : 63.615379333496094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3979198932647705; Test perplexity : 6.762115001678467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 9; Train loss : 3.4454095363616943; Train perplexity : 53.262733459472656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.38611555099487305; Test perplexity : 5.94638729095459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 10; Train loss : 3.320995807647705; Train perplexity : 45.7969856262207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3767746090888977; Test perplexity : 5.371668815612793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 11; Train loss : 3.2139475345611572; Train perplexity : 40.21280288696289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3691519498825073; Test perplexity : 4.943988800048828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 12; Train loss : 3.1200125217437744; Train perplexity : 35.8565559387207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.36221247911453247; Test perplexity : 4.584655284881592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 13; Train loss : 3.0367374420166016; Train perplexity : 32.384788513183594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.35776287317276; Test perplexity : 4.367166042327881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 14; Train loss : 2.961594581604004; Train perplexity : 29.563318252563477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.35282278060913086; Test perplexity : 4.139503479003906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 15; Train loss : 2.891826868057251; Train perplexity : 27.144344329833984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.34837034344673157; Test perplexity : 3.944704532623291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 16; Train loss : 2.8280301094055176; Train perplexity : 25.105634689331055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3451247811317444; Test perplexity : 3.808554172515869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 17; Train loss : 2.769484043121338; Train perplexity : 23.374792098999023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.34226739406585693; Test perplexity : 3.6922101974487305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 18; Train loss : 2.7163095474243164; Train perplexity : 21.909343719482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3403218984603882; Test perplexity : 3.6153910160064697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 19; Train loss : 2.6653335094451904; Train perplexity : 20.58625030517578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3384184241294861; Test perplexity : 3.541940212249756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 20; Train loss : 2.6197264194488525; Train perplexity : 19.474754333496094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.33711928129196167; Test perplexity : 3.493241786956787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 21; Train loss : 2.5878522396087646; Train perplexity : 18.7098331451416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3353009819984436; Test perplexity : 3.4251060485839844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:25,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 22; Train loss : 2.5458481311798096; Train perplexity : 17.78765869140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3348878026008606; Test perplexity : 3.409022569656372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 23; Train loss : 2.514137029647827; Train perplexity : 17.093046188354492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3348785936832428; Test perplexity : 3.4110562801361084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 24; Train loss : 2.4695451259613037; Train perplexity : 16.21106719970703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3332764506340027; Test perplexity : 3.3515939712524414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 25; Train loss : 2.429314613342285; Train perplexity : 15.43126392364502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.33062103390693665; Test perplexity : 3.2569634914398193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 26; Train loss : 2.393317222595215; Train perplexity : 14.766615867614746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3299965262413025; Test perplexity : 3.2351467609405518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 27; Train loss : 2.3564834594726562; Train perplexity : 14.122121810913086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.32945239543914795; Test perplexity : 3.2159688472747803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 28; Train loss : 2.318119525909424; Train perplexity : 13.48011302947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.32958969473838806; Test perplexity : 3.2199923992156982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 29; Train loss : 2.2831332683563232; Train perplexity : 12.92081356048584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3294069766998291; Test perplexity : 3.212521553039551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 30; Train loss : 2.2517220973968506; Train perplexity : 12.439105033874512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.33069461584091187; Test perplexity : 3.256990909576416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 31; Train loss : 2.2230589389801025; Train perplexity : 12.019454002380371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3306044936180115; Test perplexity : 3.2580161094665527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 32; Train loss : 2.2030696868896484; Train perplexity : 11.745024681091309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.32974910736083984; Test perplexity : 3.230086326599121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 33; Train loss : 2.197511911392212; Train perplexity : 11.678101539611816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.342887818813324; Test perplexity : 3.7255446910858154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 34; Train loss : 2.1601693630218506; Train perplexity : 11.136058807373047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3327842354774475; Test perplexity : 3.33793306350708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 35; Train loss : 2.121854782104492; Train perplexity : 10.626585006713867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3329025208950043; Test perplexity : 3.342803716659546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 36; Train loss : 2.088897466659546; Train perplexity : 10.20627212524414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3327288031578064; Test perplexity : 3.335421323776245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:25,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 37; Train loss : 2.053839683532715; Train perplexity : 9.786166191101074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3349001407623291; Test perplexity : 3.413177728652954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 38; Train loss : 2.026627540588379; Train perplexity : 9.470224380493164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.338936984539032; Test perplexity : 3.568413734436035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 39; Train loss : 2.014310598373413; Train perplexity : 9.320809364318848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.33412259817123413; Test perplexity : 3.386307954788208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 40; Train loss : 2.0043258666992188; Train perplexity : 9.215474128723145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3384207487106323; Test perplexity : 3.5514698028564453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 41; Train loss : 1.9758613109588623; Train perplexity : 8.902186393737793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.33758771419525146; Test perplexity : 3.514464855194092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 42; Train loss : 1.9720653295516968; Train perplexity : 8.872456550598145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3365648090839386; Test perplexity : 3.4768776893615723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 43; Train loss : 1.991978645324707; Train perplexity : 9.085957527160645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.33215248584747314; Test perplexity : 3.3222453594207764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 44; Train loss : 1.9201436042785645; Train perplexity : 8.329696655273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3341189920902252; Test perplexity : 3.3929595947265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 45; Train loss : 1.8784947395324707; Train perplexity : 7.921506404876709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.33578673005104065; Test perplexity : 3.455756664276123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:24,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 46; Train loss : 1.8443560600280762; Train perplexity : 7.603034973144531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.3384881019592285; Test perplexity : 3.557844638824463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [01:10,  1.56s/it]"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_perplexity = []\n",
    "test_loss = []\n",
    "test_perplexity = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_perplexity = 0\n",
    "    epoch_test_loss = 0\n",
    "    epoch_test_perplexity = 0\n",
    "    for batch_train_images, batch_train_sequences, batched_train_length in tqdm(zip(train_images,train_sequences,train_length)):\n",
    "        batched_train_loss, batched_train_perplexity = train_step(batch_train_images,batch_train_sequences,batched_train_length, optimizer)\n",
    "        epoch_train_loss+=batched_train_loss\n",
    "        epoch_train_perplexity+=batched_train_perplexity\n",
    "    epoch_train_loss = epoch_train_loss/batch_size\n",
    "    epoch_train_perplexity =epoch_train_perplexity/batch_size\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    train_perplexity.append(epoch_train_perplexity)\n",
    "    print('Finished epoch {}; Train loss : {}; Train perplexity : {}'.format(epoch,epoch_train_loss,epoch_train_perplexity))\n",
    "    for batch_test_images, batch_test_sequences, batched_test_length in zip(test_images,test_sequences,test_length):\n",
    "        batched_test_loss, batched_test_perplexity = evaluate(batch_test_images,batch_test_sequences,batched_test_length, optimizer)\n",
    "        epoch_test_loss+=batched_test_loss\n",
    "        epoch_test_perplexity+=batched_test_perplexity\n",
    "    epoch_test_loss = epoch_test_loss/batch_size\n",
    "    epoch_test_perplexity =epoch_test_perplexity/batch_size\n",
    "    test_perplexity.append(epoch_test_perplexity)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    print('Test loss : {}; Test perplexity : {}'.format(epoch_test_loss,epoch_test_perplexity))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2f4b0",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a661028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, encoder: tf.keras.Model,\n",
    "                 decoder: tf.keras.Model,\n",
    "                 start_token: int,\n",
    "                 end_token: int,\n",
    "                 max_len: int = 10, ):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.max_len = max_len\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "\n",
    "    def decode(self, input):\n",
    "        pass\n",
    "\n",
    "\n",
    "class GreedyDecoder(Decoder):\n",
    "    def __init__(self, encoder: tf.keras.Model,\n",
    "                 decoder: tf.keras.Model,\n",
    "                 start_token: int,\n",
    "                 end_token: int,\n",
    "                 max_len: int = 10,\n",
    "                 ):\n",
    "        super().__init__(encoder,\n",
    "                         decoder,\n",
    "                         start_token,\n",
    "                         end_token,\n",
    "                         max_len\n",
    "                         )\n",
    "\n",
    "    def decode(self, input, max_len_output=50):\n",
    "        initial_state = self.encoder(np.expand_dims(input, axis=0))\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = self.start_token\n",
    "\n",
    "        res = []\n",
    "        while True:\n",
    "            # Sample a token\n",
    "            output, initial_state = self.decoder(target_seq,initial_state)\n",
    "            sampled_token_index = np.argmax(output)\n",
    "\n",
    "            if len(res) > max_len_output or sampled_token_index == self.end_token:\n",
    "                break\n",
    "\n",
    "            res.append(sampled_token_index)\n",
    "\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "       \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchDecoder(Decoder):\n",
    "    def __init__(self, encoder: tf.keras.Model,\n",
    "                 decoder: tf.keras.Model,\n",
    "                 start_token: int,\n",
    "                 end_token: int,\n",
    "                 max_len: int = 10,\n",
    "                 ):\n",
    "        super().__init__(encoder,\n",
    "                         decoder,\n",
    "                         start_token,\n",
    "                         end_token,\n",
    "                         max_len\n",
    "                         )\n",
    "\n",
    "    def decode(self, input, beam_size=3):\n",
    "        start = [self.start_token]\n",
    "        initial_state = self.encoder(np.expand_dims(input,axis=0))\n",
    "\n",
    "\n",
    "        start_word = [[start, 0.0, initial_state]]\n",
    "\n",
    "        while len(start_word[0][0]) < self.max_len:\n",
    "            temp = []\n",
    "            for s in start_word:\n",
    "                target_seq = np.array([[s[0][-1]]])\n",
    "                initial_state = s[-1]\n",
    "                output, initial_state= self.decoder(target_seq, initial_state)\n",
    "                output = np.hstack(output)\n",
    "                output = tf.nn.softmax(output).numpy()\n",
    "                word_preds = np.argsort(output)[-beam_size:]\n",
    "\n",
    "                for w in word_preds:\n",
    "                    next_cap, prob = s[0][:], s[1]\n",
    "                    next_cap.append(w)\n",
    "                    prob += output[w]\n",
    "                    temp.append([next_cap, prob, initial_state])\n",
    "\n",
    "            start_word = temp\n",
    "            # Sorting according to the probabilities\n",
    "            start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
    "            # Getting the top words\n",
    "            start_word = start_word[-beam_size:]\n",
    "\n",
    "        start_word = start_word[-1][0]\n",
    "\n",
    "        final_caption = []\n",
    "\n",
    "        for i in start_word:\n",
    "            if i != self.end_token:\n",
    "                final_caption.append(i)\n",
    "            else:\n",
    "                break\n",
    "        return final_caption[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50618500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, decoder, inverse_vocab,\n",
    "           beam_size=None):\n",
    "    if beam_size:\n",
    "        result = decoder.decode(data, beam_size=beam_size)\n",
    "    else:\n",
    "        result = decoder.decode(data)\n",
    "    return ' '.join([inverse_vocab[i] for i in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a08d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_decoder = GreedyDecoder(conv_encoder, lstm_decoder, vocab[start_token], vocab[end_token],\n",
    "             max_len=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_decoder = BeamSearchDecoder(conv_encoder, lstm_decoder, vocab[start_token], vocab[end_token],\n",
    "             max_len=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfeba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(sample, greedy_decoder, inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(sample, beam_decoder, inverse_vocab, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e609d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
